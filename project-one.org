#+Title: Project One
#+Author: Simon Schnake
#+LATEX_HEADER: \usepackage{physics}
#+LATEX_HEADER: \usepackage{amssymb}
#+Inlineimages
#+OPTIONS: toc:nil

* Setup                                                            :noexport:
Here are the needed packages. Also to config matplotlib for latex export
#+BEGIN_SRC ipython :session one :results raw drawer :exports none :eval no-export
  import matplotlib as mpl
  import matplotlib.pylab as plt
  # mpl.rcParams['text.usetex'] = True
  # mpl.rcParams['text.latex.preamble'] = [r'\usepackage{amsmath}']
  # mpl.rcParams['mathtext.fontset'] = 'stix'
  # mpl.rcParams['font.family'] = 'STIXGeneral'

  %matplotlib inline
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[1]:
:END:

* Loading Data                                                     :noexport:
#+BEGIN_SRC ipython :session :results raw drawer :exports none :eval no-export
import h5py
data = h5py.File("../data/p-0920.h5")
X_test = data['test']['X']
Y_test = data['test']['Y']
X_train = data['train']['X']
Y_train = data['train']['Y']
#+END_SRC

#+RESULTS:
:RESULTS:
# Out[2]:
:END:

#+BEGIN_SRC ipython :session one :results raw drawer
  import numpy as np
  x = np.arange(0., 10., 0.1)
  y = x*x + 5
  plt.plot(x, y, 'k.')
#+END_SRC
* Experiment Setup
Comparing different models
-
- Results charged particles in each scintialor cell
- true energy

#+BEGIN_SRC ipython :session :results raw drawer :exports none :eval no-export
import numpy as np
tracks = np.sum(X_test[:1000], axis=1)
energies = np.transpose(Y_test[:1000])[0]

plt.plot(energies, tracks, 'r.', alpha=0.3)
plt.xlabel(r'$p_{\text{in}}$ [GeV]')
plt.ylabel(r'$n(p_{\text{in}})$')
#+END_SRC

* Linear Fit
A traditional way of calibrating the neural net would be to sum over all scintilator cells and perfom
a linear fit to the energy.
\[E = c_1\sum_i n_i + c_2\]
#+BEGIN_SRC ipython :session :results raw drawer :exports none :eval no-export

#+END_SRC

* First Network
We are starting with a dense neural network and training
* Are we learning the shape?
** TODO divide the incoming cells by the total sum
* Data Augmentation
One of the biggest issues with the setup is that it
leads to fast overfitting models. To compensate this, there are
different ways. One way is to artificially increase the dataset by
data augmentation. Data Augmentation means generating new data by transformation of the given data.
TODO <- BESSER ERKLÃ„REN.
Aneasy to understand example is shown in the image of the cat.  Examples
of data augmentation are every form of flipping, rotations or
cutting. In the perspective of a physicist, data augmentation could be
interpreted as a form of making the data invariant under symmetry
transformations. This is of course only a subset of the possible ways
of data augmentation, but it should be enough for our
application. Calorimeter events should be invariant under rotations
perpendicular to the direction of the incoming particle. Our image of
the physical process is processed in rectangular structures, which
makes only rotations around $\frac{\pi}{2}$ valid transformations.  To
reduce computation and data costs we randomly apply this
transformations on incoming data into our network. So we do not
tranform data we are not training on and we are not storing additional
transformed datasets.

** TODO Einbauen

* Result
* Problem
* Analytical Solution
* Adverserial Solution
* Correction
