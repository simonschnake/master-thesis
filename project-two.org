* Setup                                                            :noexport:

Here are the needed packages. Also to config matplotlib for latex export
#+BEGIN_SRC jupyter-python :async "yes" :session "py" :results raw drawer :exports none :eval no-export
  import numpy as np 

  from scipy.optimize import leastsq
  import matplotlib as mpl
  import matplotlib.pyplot as plt
  mpl.rcParams['text.usetex'] = True
  mpl.rcParams['text.latex.preamble'] = [r'\usepackage{amsmath}']
  mpl.rcParams['mathtext.fontset'] = 'stix'
  mpl.rcParams['font.family'] = 'STIXGeneral'
  mpl.rcParams['font.size'] = 15
  mpl.rcParams['axes.labelsize'] = 15

  %matplotlib inline
  import pickle

  # Loading Data

  dense_res = pickle.load(open('./results/dense_results.p', 'rb'))
  conv_res = pickle.load(open('./results/conv_results.p', 'rb'))
  adv_res = pickle.load(open('./results/adv_results.p', 'rb'))
  # linear fit
  leng = len(dense_res['y_true']['raw'])
  sum_n = pickle.load(open('./results/sum_n.p', 'rb'))[:leng]

  inv_fitfunc = lambda c , x: (x-c[1])/c[0]

  fitfunc = lambda c , x: (x-c[1])/c[0]
  errfunc = lambda c , x, y: (y - fitfunc(c, x))
  out = leastsq(errfunc, [0.1, 0.0], args=(dense_res['y_true']['raw'], sum_n), full_output=1)

  c_fit = out[0]
#+END_SRC

#+RESULTS:
:RESULTS:
:END:

* Loss Raw

#+BEGIN_SRC jupyter-python :async "yes" :session "py" :results raw drawer :exports none :eval no-export
  history = dense_res['history']
  conv_history = conv_res['history']

  epochs = range(len(history['loss']))
  fig, ax = plt.subplots()
  ax.spines['top'].set_visible(False)
  # ax.spines['bottom'].set_visible(False)
  ax.spines['right'].set_visible(False)
  # ax.spines['left'].set_visible(False)
  plt.tick_params(axis='both', which='both', bottom=True, top=False,
		  labelbottom=True, left=True, right=False, labelleft=True)
  # ax.xaxis.set_major_formatter(plt.FuncFormatter('{:.0f}'.format))

  plt.plot(epochs, history['loss'][:len(epochs)], 'k-')
  plt.plot(epochs, history['val_loss'][:len(epochs)], '-', color='#BF616A')
  # plt.plot(epochs, history['da_loss'], 'k-')
  # plt.plot(epochs, history['da_val_loss'], '-', color='#1f77b4')

  plt.text(float(epochs[-1])+0.5, history['loss'][-1], 'training loss', ha='left', va='center', size=16)
  plt.text(float(epochs[-1])+0.5, history['val_loss'][-1], 'validation loss', ha='left', va='center', size=16, color='#BF616A')

  plt.xlabel('epochs')
  plt.ylabel('loss')
  plt.ylim([0.1, 1.0])
  plt.savefig('images/dense_loss.pdf', bbox_inches = 'tight')
#+END_SRC

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/a393232e9bd5a90162d6dbd989d2259e0fdd78b1.png]]
:END:

* Scatter Plot Raw
#+BEGIN_SRC jupyter-python :async "yes" :session "py" :results raw drawer :exports none :eval no-export

  func = lambda c, x: c[0]*x+c[1] 
  fig, ax = plt.subplots()
  plt.plot(dense_res['y_true']['raw'][:10000], func(c_fit, sum_n)[:10000], '.', alpha=0.25, markersize=3, color='#1f77b4')
  plt.plot(dense_res['y_true']['raw'][:10000], dense_res['y_pred']['raw'][:10000], 'k.', alpha=0.25, markersize=3)
  # plt.ylim([-5., 5])
  # plt.xlim([0.,10])
  plt.ylabel(r'$E_{\text{pred}}$ [GeV]')
  plt.xlabel(r'$E_{\text{true}}$ [GeV]')

  plt.text(7, 3.5, 'neural net', ha='left', va='center', size=17)
  plt.text(7.5, 12, 'linear fit', ha='left', va='center', size=17, color='#1f77b4')

  ax.spines["top"].set_visible(False)
  ax.spines["right"].set_visible(False)  

  plt.savefig('images/dense_scatter.pdf', bbox_inches = 'tight')
#+END_SRC

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/09db3de8cd9991e9be707565dc94642fce4348ef.png]]
:END:

* Results Raw

#+BEGIN_SRC jupyter-python :async "yes" :session "py" :results raw drawer :exports none :eval no-export
  n = 20
  from src.binned_estimation import binned_estimation
  from scipy.stats import norm

  res = binned_estimation(dense_res['y_true']['raw'], func(c_fit, sum_n), bins = 20)
  y_f, mu_f, sigma_f, std_mu_f, std_sigma_f = res[0], res[1], res[2], res[3], res[4]


  fig = plt.figure()
  ax = fig.add_subplot(2,1,1)

  # mu plot
  ax.plot(y_f, mu_f - y_f, '-', color='#1f77b4')
  ax.plot(dense_res['y']['raw'], dense_res['mu']['raw'] - dense_res['y']['raw'], 'k-')
  plt.text(y_f[-1] + 0.1, mu_f[-1] - y_f[-1]+0.02, 'linear fit', ha='left', va='center', size=15, color='#1f77b4')
  plt.text(dense_res['y']['raw'][-1] + 0.1, dense_res['mu']['raw'][-1] - dense_res['y']['raw'][-1]-0.02, 'neural net', ha='left', va='center', size=15)
  plt.ylabel(r'$\mu - E_{\text{true}}$ [GeV]')
  plt.ylim([-0.8, 0.8])
  ax.xaxis.set_ticks([])
  ax.spines["top"].set_visible(False)
  ax.spines["right"].set_visible(False)
  ax.spines["bottom"].set_visible(False)


  # sigma/sqrt(y_true) plot

  ax = fig.add_subplot(2,1,2)
  ax.plot(y_f, sigma_f / np.sqrt(y_f), '-', color='#1f77b4')
  ax.plot(dense_res['y']['raw'], dense_res['sigma']['raw'] / np.sqrt(dense_res['y']['raw']), 'k-')
  plt.ylabel(r'$\sigma / \sqrt{E_{\text{true}}}$')
  plt.xlabel(r'$E_{\text{true}}$ [GeV]')
  ax.spines["top"].set_visible(False)
  ax.spines["right"].set_visible(False)

  plt.text(y_f[-1] + 0.1, sigma_f[-1] / np.sqrt(y_f[-1])+0.01, 'linear fit', ha='left', va='center', size=15, color='#1f77b4')
  plt.text(dense_res['y']['raw'][-1] + 0.1, dense_res['sigma']['raw'][-1] / np.sqrt(dense_res['y']['raw'][-1])-0.01, 'neural net', ha='left', va='center', size=15)
  plt.ylim([0., 0.5])
  # plt.savefig('images/dense_res.pdf', bbox_inches = 'tight')
#+END_SRC

#+RESULTS:
:RESULTS:
: 0.499909334
| 0.0 | 0.5 |
[[file:./.ob-jupyter/45c7cfc9931ea24fc6ea30f4040ff80babe5fa6e.png]]
:END:

* Loss Data Augmentation

#+BEGIN_SRC jupyter-python :async "yes" :session "py" :results raw drawer :exports none :eval no-export
history = dense_res['history']
conv_history = conv_res['history']
epochs = range(len(history['da_loss']))

fig, ax = plt.subplots()
ax.spines['top'].set_visible(False)
ax.spines['bottom'].set_visible(False)
ax.spines['right'].set_visible(False)
ax.spines['left'].set_visible(False)
plt.tick_params(axis='both', which='both', bottom=False, top=False,
                labelbottom=True, left=True, right=False, labelleft=True)
ax.xaxis.set_major_formatter(plt.FuncFormatter('{:.0f}'.format))
plt.plot(epochs, history['loss'], '-', color='#433376')
plt.plot(epochs, history['val_loss'], '-', color='#8A7FB0')
plt.plot(epochs, history['da_loss'], '-', color='#A10D0D')
plt.plot(epochs, history['da_val_loss'], '-', color='#DD4A4A')

plt.text(float(epochs[-1])+0.5, history['loss'][-1]-0.02, 'neural net train', ha='left', va='center', size=15, color='#433376')
plt.text(float(epochs[-1])+0.5, history['val_loss'][-1]+0.02, 'neural net val', ha='left', va='center', size=15, color='#8A7FB0')
plt.text(float(epochs[-1])+0.5, history['da_loss'][-1]-0.02, 'data augment train', ha='left', va='center', size=15, color='#A10D0D')
plt.text(float(epochs[-1])+0.5, history['da_val_loss'][-1]+0.02, 'data augment val', ha='left', va='center', size=15, color='#DD4A4A')

plt.xlabel('epochs')
plt.ylabel('loss')
plt.ylim([0.1, 1.2])
plt.savefig('images/data_augment_loss.pdf', bbox_inches = 'tight')
#+END_SRC

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/85df140ee606d5c62fb0885493d8746b9491b43d.png]]
:END:

* Scatter Likelihood

#+BEGIN_SRC jupyter-python :async "yes" :session "py" :results raw drawer :exports none :eval no-export

  func = lambda c, x: c[0]*x+c[1] 
  fig, ax = plt.subplots()
  plt.plot(dense_res['y_true']['raw'][:10000], func(c_fit, sum_n)[:10000], '.', alpha=0.25, markersize=3, color='#1f77b4')
  plt.plot(dense_res['y_true']['likeli'][:10000], dense_res['y_pred']['likeli'][:10000], 'k.', alpha=0.25, markersize=3)
  # plt.ylim([-5., 5])
  # plt.xlim([0.,10])
  plt.ylabel(r'$E_{\text{pred}} - E_{\text{true}}$ [GeV]')
  plt.xlabel(r'$E_{\text{true}}$ [GeV]')

  plt.text(7, 3.5, 'neural net', ha='left', va='center', size=17)
  plt.text(7.5, 12, 'linear fit', ha='left', va='center', size=17, color='#1f77b4')

  ax.spines["top"].set_visible(False)
  ax.spines["right"].set_visible(False)  
  ax.spines["left"].set_visible(False)
  ax.spines["bottom"].set_visible(False)  
#+END_SRC

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/88f1ac5fae2082560366f3c529f27d868d1883d6.png]]
:END:

* Comparison Loss Functions

#+BEGIN_SRC jupyter-python :async "yes" :session "py" :results raw drawer :exports none :eval no-export
  fig, ax = plt.subplots()

  plt.plot(y_f, mu_f - y_f, '-', color='#c71585')
  plt.plot(dense_res['y']['da'], dense_res['mu']['da'] - dense_res['y']['raw'], '-', color='#D08770', )
  plt.plot(dense_res['y']['likeli'], dense_res['mu']['likeli'] - dense_res['y']['likeli'], '-', color='#3B4252', )

  plt.text(y_f[-1] + 0.1, mu_f[-1] - y_f[-1], 'linear fit', ha='left', va='center', size=15,  color='#c71585', weight='bold')
  plt.text(dense_res['y']['da'][-1] + 0.1, dense_res['mu']['da'][-1] - dense_res['y']['raw'][-1], 'mse', ha='left', va='center', size=15,  color='#D08770', weight='bold')
  plt.text(dense_res['y']['likeli'][-1] + 0.1, dense_res['mu']['likeli'][-1] - dense_res['y']['likeli'][-1], 'likelihood', ha='left', va='center', size=15,  color='#3B4252', weight='bold')

  plt.ylabel(r'$\mu - E_{\text{true}}$ [GeV]')
  plt.xlabel(r'$E_{\text{true}}$ [GeV]')
  plt.ylim([-1., 0.2])

  ax.spines["top"].set_visible(False)
  ax.spines["right"].set_visible(False)


  plt.savefig('images/loss_comparison.pdf', bbox_inches = 'tight')
#+END_SRC

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/74e7f1e1744aa7ad859a4c389156de9885cd6932.png]]
:END:

* Comparison Fully Connected Net & Conv Net

#+BEGIN_SRC jupyter-python :async "yes" :session "py" :results raw drawer :exports none :eval no-export
  fig, ax = plt.subplots()

  plt.plot(y_f, sigma_f / np.sqrt(y_f), '-', color='#c71585')
  plt.plot(dense_res['y']['likeli'], dense_res['sigma']['likeli'] / np.sqrt(conv_res['y']['likeli']), '-', color='#D08770')
  plt.plot(conv_res['y']['likeli'], conv_res['sigma']['likeli'] / np.sqrt(conv_res['y']['likeli']), '-', color='#3B4252')

  plt.text(y_f[-1] + 0.1, sigma_f[-1]/np.sqrt(y_f[-1]), 'linear fit', ha='left', va='center', size=15,  color='#c71585', weight='bold')
  plt.text(dense_res['y']['likeli'][-1] + 0.1, dense_res['sigma']['likeli'][-1]/np.sqrt(dense_res['y']['likeli'][-1]), 'dense', ha='left', va='center', size=15,  color='#D08770', weight='bold')
  plt.text(conv_res['y']['likeli'][-1] + 0.1, conv_res['sigma']['likeli'][-1]/np.sqrt(conv_res['y']['likeli'][-1]), 'conv', ha='left', va='center', size=15,  color='#3B4252', weight='bold')

  plt.ylabel(r'$\sigma/\sqrt{E_{\text{true}}}$')
  plt.xlabel(r'$E_{\text{true}}$ [GeV]')
  plt.ylim([0.25, 0.5])

  print(np.mean(sigma_f/np.sqrt(y_f)))
  print(np.mean(dense_res['sigma']['likeli'] / np.sqrt(conv_res['y']['likeli'])))
  print(np.mean(conv_res['sigma']['likeli'] / np.sqrt(conv_res['y']['likeli'])))

  ax.spines["top"].set_visible(False)
  ax.spines["right"].set_visible(False)

  plt.savefig('images/arch_comparison.pdf', bbox_inches = 'tight')
#+END_SRC

#+RESULTS:
:RESULTS:
: 0.36334587812383645
: 0.3266467786504851
: 0.31944836012595457
[[file:./.ob-jupyter/39baac73e9fdcc4c2e127385016fcae83e4f1072.png]]
:END:

* Adversarial Scatter
#+BEGIN_SRC jupyter-python :async "yes" :session "py" :results raw drawer :exports none :eval no-export

  func = lambda c, x: c[0]*x+c[1] 

  fig = plt.figure(figsize=(20,10))

  for i in range(9):
      ax = fig.add_subplot(3,3,i+1)

      ax.plot(adv_res['y_true'][:10000], func(c_fit, sum_n)[:10000], '.', alpha=0.25, markersize=3, color='#1f77b4')
      ax.plot(adv_res['y_true'][:10000], adv_res['y_pred'][i][:10000], 'k.', alpha=0.25, markersize=3)
      plt.ylim([0., 12.])
      ax.xaxis.set_ticks([])
      ax.yaxis.set_ticks([])
      # plt.xlim([0.,10])
      #plt.ylabel(r'$E_{\text{pred}} - E_{\text{true}}$ [GeV]')
      #plt.xlabel(r'$E_{\text{true}}$ [GeV]')

      plt.text(2.5, 8, str(i+1), ha='left', va='center', size=20)
      #plt.text(7.5, 12, 'linear fit', ha='left', va='center', size=17, color='#1f77b4')

      ax.spines["top"].set_visible(False)
      ax.spines["right"].set_visible(False)  
      ax.spines["left"].set_visible(False)
      ax.spines["bottom"].set_visible(False)  
  plt.savefig('images/adv_scatter.pdf', bbox_inches = 'tight')
#+END_SRC

#+RESULTS:
:RESULTS:
[[file:./.ob-jupyter/c00b14da88235e1c0fb0dc34ba6b1a2fc65fcf35.png]]
:END:



